{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network analysis\n",
    "I have already tried to use the raw correlation values between brain regions as features for predicting adhd diagnosis. I will now try a different approach by calculating network measures for each subject's connectivity matrix. Network measures refer to specific graph summary statistics such as functional integration, functional segregation, centrality, and resilience. NetworkX implements many of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn_matrices():\n",
    "    file_names = os.listdir(\"data/ADHD200_CC200\")\n",
    "\n",
    "    cm_file_re = r\"^\\S+connectivity_matrix_file\\.txt$\"\n",
    "\n",
    "    conn_matrices = OrderedDict()\n",
    "    for file_name in file_names:\n",
    "        if re.match(cm_file_re, file_name):\n",
    "            id_ = \"\".join(file_name.split(\"_\")[:-3])\n",
    "        \n",
    "            cm = np.empty((190,190))\n",
    "            with open(\"data/ADHD200_CC200/{}\".format(file_name)) as f:\n",
    "                for idx, row in enumerate(f):\n",
    "                    row = row.strip().split(\" \")\n",
    "                    row = list(map(np.float, row))\n",
    "                    cm[idx, :] = row\n",
    "        \n",
    "            conn_matrices[id_] = cm\n",
    "    return conn_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regions():\n",
    "    \"\"\"\n",
    "    Gets the names of the regions (in order of appearance in connectivity matrix). \n",
    "    All files have the same order of regions, so we only to need to get this once.\n",
    "    Some region names are repeated because there are multiple points within that region,\n",
    "        so numbers are appended to the region names to distinguish them.\n",
    "    \n",
    "    returns a list of strings\n",
    "    \"\"\"\n",
    "    regions_path = \"data/ADHD200_CC200/KKI_1018959_region_names_abbrev_file.txt\"\n",
    "    regions = []\n",
    "    with open(regions_path, \"r\") as f:\n",
    "        regions = [region.strip().replace(\" \", \"_\") for region in f]\n",
    "    names = defaultdict(int)\n",
    "    distinct_region_names = []\n",
    "    for region in regions:\n",
    "        distinct_region_names.append(region+\"_\"+str(names[region]))\n",
    "        names[region] += 1\n",
    "    return distinct_region_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_names = get_regions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_matrices = get_conn_matrices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate graph statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the measures have already been calculated and saved, just load them\n",
    "load_measures = False\n",
    "if load_measures:\n",
    "    with open(\"conn_mat_measures_local.pkl\", \"rb\") as f:\n",
    "        measures = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(g, thresh):\n",
    "    \"\"\"\n",
    "    Turn a weighted graph into an unweighted graph with the specified threshold.\n",
    "    All edges less than the threshold become 0, while those above the threshold become 1.\n",
    "    \"\"\"\n",
    "    return (g > thresh).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize each matrix\n",
    "subjects = list(conn_matrices.keys())\n",
    "binarized = OrderedDict()\n",
    "for idx, subject in enumerate(subjects):\n",
    "    cm = conn_matrices[subject]\n",
    "    uw = binarize(cm, .2)\n",
    "    binarized[subject] = uw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_graphs_local(binarized):\n",
    "    \"\"\"\n",
    "    Calculate predetermined graph analytics for each graph and return then in a dict of lists.\n",
    "    measures: degree centrality, closeness centrality, and nodal clustering coefficient\n",
    "    \n",
    "    These measures are calculated for each node in the network, so a list of the measures is created for each network\n",
    "    \"\"\"\n",
    "    measures = {}\n",
    "    \n",
    "    print(\"calculating degree centralities\")\n",
    "    measures[\"degree_centrality\"] = [nx.degree_centrality(nx.Graph(bu)) for bu in binarized.values()]\n",
    "    \n",
    "    print(\"calculating closeness centralities\")\n",
    "    measures[\"closeness_centrality\"] = [nx.closeness_centrality(nx.Graph(bu)) for bu in binarized.values()]\n",
    "    \n",
    "    print(\"calculating clustering coefficients\")\n",
    "    measures[\"clustering_coefficient\"] = [nx.clustering(nx.Graph(bu)) for bu in binarized.values()]\n",
    "    \n",
    "    return measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating degree centralities\n",
      "calculating closeness centralities\n",
      "calculating clustering coefficients\n"
     ]
    }
   ],
   "source": [
    "# get measures for each of the connectivity matrices\n",
    "measures = measure_graphs_local(binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the measurements to a standard format table: subjects x features\n",
    "features = defaultdict(list)\n",
    "for measure in list(measures.keys()): # for each measure type (degree centrality, closeness centrality, clustering)\n",
    "    for measures_dict in measures[measure]: # for each subject's dict of measures (one measure for each node)\n",
    "        for key, val in measures_dict.items(): # for the (node idx, measurement value) in the subjects dict\n",
    "            features[\"node_{}_{}\".format(key, measure)].append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_node_features = pd.DataFrame(features, index=list(conn_matrices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_local_node_features = True\n",
    "if save_local_node_features:\n",
    "    with open(\"all_local_node_features.pkl\", \"wb\") as f:\n",
    "        pkl.dump(local_node_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
