{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Network analysis\n",
    "I have already tried to use the raw correlation values between brain regions as features for predicting adhd diagnosis. I will now try a different approach by calculating network measures for each subject's connectivity matrix. Network measures refer to specific graph summary statistics such as functional integration, functional segregation, centrality, and resilience. NetworkX implements many of these.\n",
    "\n",
    "I will try global network measures in this notebook, and local network measures in another.\n",
    "\n",
    "### Outcome:\n",
    "None of the global measures showed much value in predicting ADHD. These measures were not used in my final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn_matrices():\n",
    "    file_names = os.listdir(\"data/ADHD200_CC200\")\n",
    "\n",
    "    cm_file_re = r\"^\\S+connectivity_matrix_file\\.txt$\"\n",
    "\n",
    "    conn_matrices = OrderedDict()\n",
    "    for file_name in file_names:\n",
    "        if re.match(cm_file_re, file_name):\n",
    "            id_ = \"\".join(file_name.split(\"_\")[:-3])\n",
    "        \n",
    "            cm = np.empty((190,190))\n",
    "            with open(\"data/ADHD200_CC200/{}\".format(file_name)) as f:\n",
    "                for idx, row in enumerate(f):\n",
    "                    row = row.strip().split(\" \")\n",
    "                    row = list(map(np.float, row))\n",
    "                    cm[idx, :] = row\n",
    "        \n",
    "            conn_matrices[id_] = cm\n",
    "    return conn_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regions():\n",
    "    \"\"\"\n",
    "    Gets the names of the regions (in order of appearance in connectivity matrix). \n",
    "    All files have the same order of regions, so we only to need to get this once.\n",
    "    Some region names are repeated because there are multiple points within that region,\n",
    "        so numbers are appended to the region names to distinguish them.\n",
    "    \n",
    "    returns a list of strings\n",
    "    \"\"\"\n",
    "    regions_path = \"data/ADHD200_CC200/KKI_1018959_region_names_full_file.txt\"\n",
    "    regions = []\n",
    "    with open(regions_path, \"r\") as f:\n",
    "        regions = [region.strip().replace(\" \", \"_\") for region in f]\n",
    "    names = defaultdict(int)\n",
    "    distinct_region_names = []\n",
    "    for region in regions:\n",
    "        distinct_region_names.append(region+\"_\"+str(names[region]))\n",
    "        names[region] += 1\n",
    "    return distinct_region_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_names = get_regions()\n",
    "conn_matrices = get_conn_matrices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate graph statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the measures have already been calculated and saved, just load them\n",
    "load_measures = False\n",
    "if load_measures:\n",
    "    with open(\"conn_mat_measures.pkl\", \"rb\") as f:\n",
    "        measures = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(g, thresh):\n",
    "    \"\"\"\n",
    "    Turn a weighted graph into an unweighted graph with the specified threshold.\n",
    "    All edges less than the threshold become 0, while those above the threshold become 1.\n",
    "    \"\"\"\n",
    "    return (g > thresh).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize each matrix\n",
    "subjects = list(conn_matrices.keys())\n",
    "binarized = OrderedDict()\n",
    "for idx, subject in enumerate(subjects):\n",
    "    cm = conn_matrices[subject]\n",
    "    uw = binarize(cm, .2)\n",
    "    binarized[subject] = uw\n",
    "    \n",
    "del conn_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_graphs(binarized):\n",
    "    \"\"\"\n",
    "    Calculate predetermined graph analytics for each graph and return then in a dict of lists.\n",
    "    measures: average clustering coefficient, global efficiencies, average shortest path length\n",
    "    \n",
    "    Small-worldness (sigma or omega) is too computationally expensive to calculate, but it is a function of\n",
    "        the average shortest path length and the average clustering coefficient, so small world qualities are\n",
    "        taken into account.\n",
    "    \"\"\"\n",
    "    measures = {}\n",
    "    \n",
    "    print(\"calculating average clustering coefficients\")\n",
    "    # clustering coefficient is a measure of how frequently nodes in a graph tend to cluster together\n",
    "    measures[\"average_clustering_coef\"] = [nx.average_clustering(nx.Graph(bu)) for bu in binarized.values()]\n",
    "    \n",
    "    print(\"calculating global efficiencies\")\n",
    "    measures[\"global_efficiency\"] = [nx.global_efficiency(nx.Graph(bu)) for bu in binarized.values()]\n",
    "    \n",
    "    print(\"calculating average shortest path lengths\")\n",
    "    measures[\"average_shortest_path_length\"] = [nx.average_shortest_path_length(nx.Graph(bu)) for bu in binarized.values()]\n",
    "    \n",
    "    return measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get measures for each of the connectivity matrices\n",
    "measures = measure_graphs(binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_measures = False\n",
    "if save_measures:\n",
    "    with open(\"conn_mat_measures.pkl\", \"wb\") as f:\n",
    "        pkl.dump(measures, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up some memory\n",
    "del binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load subject data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get subject data\n",
    "with open(\"cm_table.html\", \"r\") as f:\n",
    "    table = f.read()\n",
    "\n",
    "soup = BeautifulSoup(table, \"html.parser\")\n",
    "\n",
    "rows = soup.find_all(class_=\"powerTable\")[1].tbody.find_all(\"tr\")[3:523]\n",
    "\n",
    "cols = defaultdict(list)\n",
    "for row in rows:\n",
    "    text_list = list(row.stripped_strings)\n",
    "    if len(text_list) == 13:\n",
    "        text_list.insert(7, 'na') # insert so list is standard size when that column was empty on the webpage\n",
    "    cols[\"study\"].append(text_list[2])\n",
    "    cols[\"id\"].append(text_list[3].replace(\"_\", \"\"))\n",
    "    cols[\"age\"].append(float(text_list[8]))\n",
    "    cols[\"gender\"].append(text_list[10])\n",
    "    cols[\"label\"].append(text_list[11])\n",
    "\n",
    "cols[\"gender\"] = [1 if gen == \"Male\" else 0 for gen in cols[\"gender\"]] # one hot label the gender\n",
    "subject_data = pd.DataFrame(cols)\n",
    "\n",
    "del soup\n",
    "del rows\n",
    "del cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_subject_data(subject_data, subject_order):\n",
    "    \"\"\"\n",
    "    Sorts a dataframe by the order given\n",
    "    :arg subject_data: dataframe with ADHD200 subject data\n",
    "    :arg subject_order: a list of subjects in specific order\n",
    "    \"\"\"\n",
    "    subject_data_ids = subject_data[\"id\"].values\n",
    "    subjects_order_in_subject_data = [np.where(subject_data_ids==subject)[0][0] for subject in subject_order]\n",
    "    subject_data_sort = subject_data.iloc[subjects_order_in_subject_data, :]\n",
    "    return subject_data_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_order = list(conn_matrices.keys())\n",
    "subject_data_sorted = sort_subject_data(subject_data, subject_order)\n",
    "adhd = [0 if label == \"Typically Developing\" else 1 for label in subject_data_sorted[\"label\"]]\n",
    "subject_data_sorted = subject_data_sorted.assign(adhd=adhd).drop(columns=\"label\")\n",
    "\n",
    "del subject_data\n",
    "del conn_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measures data is in same order as the subject data. Combine them.\n",
    "subject_data_measures = pd.concat([subject_data_sorted, pd.DataFrame(measures)], axis=1)\n",
    "del subject_data_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['study', 'id', 'age', 'gender', 'adhd', 'average_clustering_coef',\n",
       "       'global_efficiency', 'average_shortest_path_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_data_measures.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = subject_data_measures.drop(columns=[\"study\", \"id\", \"adhd\"]).values\n",
    "y = subject_data_measures[\"adhd\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = True\n",
    "if scale:\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc = 0.654\n",
      "test acc = 0.558\n",
      "ROC AUC = 0.499\n",
      "[[47 20]\n",
      " [26 11]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "roc_auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"train acc = {:.3f}\".format(model.score(X_train, y_train)))\n",
    "print(\"test acc = {:.3f}\".format(model.score(X_test, y_test)))\n",
    "print(\"ROC AUC = {:.3f}\".format(roc_auc))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc = 0.750\n",
      "test acc = 0.615\n",
      "ROC AUC = 0.526\n",
      "[[56 11]\n",
      " [29  8]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(max_depth=4)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "roc_auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"train acc = {:.3f}\".format(model.score(X_train, y_train)))\n",
    "print(\"test acc = {:.3f}\".format(model.score(X_test, y_test)))\n",
    "print(\"ROC AUC = {:.3f}\".format(roc_auc))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
