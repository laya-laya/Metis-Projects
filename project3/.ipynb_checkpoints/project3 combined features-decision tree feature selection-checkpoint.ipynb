{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining two feature sets\n",
    "\n",
    "This notebook duplicates tests done in the `project3 combined features.ipynb` notebook, except uses decision trees as the feature selector. Below is a description of the tests.\n",
    "\n",
    "In this notebook I will test combining two sets of features that were independently somewhat successful:\n",
    "* Connection strengths between regions (only positive values)\n",
    "* Local network statistics for each region\n",
    "\n",
    "Only the most correlated features from each of these sets will be used, chosen by decision tree feature importance.\n",
    "\n",
    "Note that the local network statistics need to be saved as a pickle file in this directory. They can be generated by running the code in `project3 network analysis - local level.ipynb`.\n",
    "\n",
    "**Ensembling** was tested with a combination of the models as well. The (mean) ROC AUC score was calculated for the cross validated training data, and for the held out test set.\n",
    "\n",
    "### Outcomes:\n",
    "Wrt feature selection:\n",
    "*\n",
    "\n",
    "Previous outcomes:\n",
    "* Combining these feature sets improved the ROC AUC and accuracy scores. These combined features were used in my final analysis.\n",
    "\n",
    "* Additionally, a soft-voting ensemble classifier with logistic regression, Naive Bayes, and RBF SVM models improved on the ROC AUC score. This ensemble model is used for my final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve, make_scorer, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#from lightgbm import LGBMClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, ADASYN\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_connection_features = True\n",
    "if load_connection_features:\n",
    "    with open(\"all_connection_features.pkl\", \"rb\") as f:\n",
    "        X = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_local_node_features.pkl\", \"rb\") as f:\n",
    "    node_measures = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, node_measures], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(columns=[\"adhd\"]), X[\"adhd\"], test_size=.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scale the data\n",
    "scale = True\n",
    "if scale:\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train positive class ratio: 0.368\n",
      "test positive class ratio: 0.356\n"
     ]
    }
   ],
   "source": [
    "# percentage of subjects with adhd in the training and testing sets\n",
    "print(\"train positive class ratio: {:.3f}\".format(np.count_nonzero(y_train == 1)/len(y_train)))\n",
    "print(\"test positive class ratio: {:.3f}\".format(np.count_nonzero(y_test == 1)/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection using random forest feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_important_features(X_tr, y_tr, X_te, num_features):\n",
    "    print(\"training random forest classifier...\")\n",
    "    rf = RandomForestClassifier(max_depth=5, n_estimators=100)\n",
    "    rf.fit(X_tr, y_tr)\n",
    "    \n",
    "    most_important_idxs = np.argsort(-rf.feature_importances_)\n",
    "    most_important_idxs = most_important_idxs[:num_features]\n",
    "    return (X_tr[:, most_important_idxs], X_te[:, most_important_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training random forest classifier...\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = most_important_features(X_train, y_train, X_test, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains the specified models and prints a confusion matrix for test set predictions\n",
    "def test_models(models, X_train, y_train, X_test, y_test):\n",
    "    for model_name in list(models.keys()):\n",
    "        m = models[model_name]\n",
    "        m.fit(X_train, y_train)\n",
    "        \n",
    "        preds = m.predict(X_test)\n",
    "        \n",
    "        roc_auc = roc_auc_score(y_test, preds)\n",
    "        \n",
    "        print(\"{}:\".format(model_name))\n",
    "        print(\"train acc = {:.3f}\".format(m.score(X_train, y_train)))\n",
    "        print(\"test acc = {:.3f}\".format(m.score(X_test, y_test)))\n",
    "        print(confusion_matrix(y_test, preds))\n",
    "        print(\"ROC AUC = {:.3f}\".format(roc_auc))\n",
    "        print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression:\n",
      "train acc = 0.887\n",
      "test acc = 0.625\n",
      "[[54 13]\n",
      " [26 11]]\n",
      "ROC AUC = 0.552\n",
      "-----------------------\n",
      "KNN:\n",
      "train acc = 0.726\n",
      "test acc = 0.654\n",
      "[[67  0]\n",
      " [36  1]]\n",
      "ROC AUC = 0.514\n",
      "-----------------------\n",
      "SVM:\n",
      "train acc = 0.986\n",
      "test acc = 0.587\n",
      "[[49 18]\n",
      " [25 12]]\n",
      "ROC AUC = 0.528\n",
      "-----------------------\n",
      "Naive Bayes:\n",
      "train acc = 0.808\n",
      "test acc = 0.529\n",
      "[[40 27]\n",
      " [22 15]]\n",
      "ROC AUC = 0.501\n",
      "-----------------------\n",
      "Random forest:\n",
      "train acc = 0.889\n",
      "test acc = 0.644\n",
      "[[66  1]\n",
      " [36  1]]\n",
      "ROC AUC = 0.506\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "models = {\"Logistic regression\": LogisticRegressionCV(),\n",
    "          \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "          \"SVM\": svm.SVC(kernel=\"rbf\"),\n",
    "          \"Naive Bayes\": GaussianNB(), \n",
    "          \"Random forest\": RandomForestClassifier(max_depth=4), \n",
    "          #\"Gradient boosting machine\": LGBMClassifier(max_depth=4)\n",
    "         }\n",
    "test_models(models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversample the minority class\n",
    "All of these classifiers have horrible positive class precision due to small positive class. If seperating subjects by gender, males already have an almost even split, this won't do anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled, y_train_resampled = RandomOverSampler(random_state=0).fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression:\n",
      "train acc = 1.000\n",
      "test acc = 0.548\n",
      "[[39 28]\n",
      " [19 18]]\n",
      "ROC AUC = 0.534\n",
      "-----------------------\n",
      "KNN:\n",
      "train acc = 0.747\n",
      "test acc = 0.596\n",
      "[[57 10]\n",
      " [32  5]]\n",
      "ROC AUC = 0.493\n",
      "-----------------------\n",
      "SVM:\n",
      "train acc = 0.998\n",
      "test acc = 0.538\n",
      "[[43 24]\n",
      " [24 13]]\n",
      "ROC AUC = 0.497\n",
      "-----------------------\n",
      "Naive Bayes:\n",
      "train acc = 0.798\n",
      "test acc = 0.519\n",
      "[[40 27]\n",
      " [23 14]]\n",
      "ROC AUC = 0.488\n",
      "-----------------------\n",
      "Random forest:\n",
      "train acc = 0.975\n",
      "test acc = 0.596\n",
      "[[52 15]\n",
      " [27 10]]\n",
      "ROC AUC = 0.523\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "models = {\"Logistic regression\": LogisticRegression(),\n",
    "          \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "          \"SVM\": svm.SVC(kernel=\"rbf\"),\n",
    "          \"Naive Bayes\": GaussianNB(), \n",
    "          \"Random forest\": RandomForestClassifier(max_depth=4), \n",
    "          #\"Gradient boosting machine\": LGBMClassifier(max_depth=4)\n",
    "         }\n",
    "test_models(models, X_train_resampled, y_train_resampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adasyn, y_adasyn = ADASYN(random_state=0).fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"Logistic regression\": LogisticRegression(),\n",
    "          \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "          \"SVM\": svm.SVC(kernel=\"rbf\"),\n",
    "          \"Naive Bayes\": GaussianNB(), \n",
    "          \"Random forest\": RandomForestClassifier(max_depth=4), \n",
    "          \"Gradient boosting machine\": LGBMClassifier(max_depth=4)\n",
    "         }\n",
    "test_models(models, X_adasyn, y_adasyn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc = 0.959\n",
      "test acc = 0.529\n",
      "ROC AUC = 0.469\n",
      "[[45 22]\n",
      " [27 10]]\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(2,), max_iter=2000)\n",
    "mlp.fit(X_train, y_train)\n",
    "print(\"train acc = {:.3f}\".format(mlp.score(X_train, y_train)))\n",
    "print(\"test acc = {:.3f}\".format(mlp.score(X_test, y_test)))\n",
    "print(\"ROC AUC = {:.3f}\".format(roc_auc_score(mlp.predict(X_test), y_test)))\n",
    "print(confusion_matrix(y_test, mlp.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc = 0.945\n",
      "test acc = 0.538\n",
      "[[41 26]\n",
      " [22 15]]\n",
      "ROC AUC = 0.508\n"
     ]
    }
   ],
   "source": [
    "estimators = [(\"Logistic regression\", LogisticRegression(C=0.0886)),\n",
    "              #(\"mlp\", MLPClassifier(hidden_layer_sizes=(2,), max_iter=2000)),\n",
    "              #(\"KNN\", KNeighborsClassifier(n_neighbors=5)),\n",
    "              (\"SVM\", svm.SVC(kernel=\"rbf\", probability=True)),\n",
    "              (\"Naive Bayes\", GaussianNB()),\n",
    "              #(\"Random forest\", RandomForestClassifier(max_depth=4)),\n",
    "              #(\"Gradient boosting machine\", LGBMClassifier(max_depth=4))\n",
    "              ]\n",
    "voter = VotingClassifier(estimators, voting=\"soft\")\n",
    "\n",
    "voter.fit(X_train, y_train)\n",
    "\n",
    "preds = voter.predict(X_test)\n",
    "roc_auc = roc_auc_score(preds, y_test)\n",
    "\n",
    "print(\"train acc = {:.3f}\".format(voter.score(X_train, y_train)))\n",
    "print(\"test acc = {:.3f}\".format(voter.score(X_test, y_test)))\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(\"ROC AUC = {:.3f}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = print_confusion_matrix(confusion_matrix(y_test, preds), class_names=[\"No ADHD\", \"ADHD\"], fontsize=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat.savefig(\"confusion_matrix.png\", dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"recall:\", recall_score(y_test, preds))\n",
    "print(\"precision:\", precision_score(y_test, preds))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = voter.predict_proba(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, probas[:,1], pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(fpr, tpr, linewidth=3)\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\", linewidth=2)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=16, labelpad=10)\n",
    "plt.ylabel(\"True\\nPositive\\nRate\", fontsize=16, rotation=0, labelpad=40)\n",
    "plt.title(\"ROC Curve\", fontsize=24)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ROC_curve.png\", dpi=200, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average cross validated scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_avg_roc_aucs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [(\"Logistic regression\", LogisticRegression(C=0.0886)),\n",
    "              (\"KNN\", KNeighborsClassifier(n_neighbors=5)),\n",
    "              (\"SVM\", svm.SVC(kernel=\"rbf\")),\n",
    "              (\"Naive Bayes\", GaussianNB()),\n",
    "              (\"Random forest\", RandomForestClassifier(max_depth=4)),\n",
    "              (\"Gradient boosting machine\", LGBMClassifier(max_depth=4)),\n",
    "              (\"mlp\", MLPClassifier(hidden_layer_sizes=(2,), max_iter=1500))]\n",
    "\n",
    "for model_name, model in models:\n",
    "    roc_scorer = make_scorer(roc_auc_score)\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring=roc_scorer, cv = 5)\n",
    "    model_avg_roc_aucs[model_name] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_avg_roc_aucs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Cross val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"Logistic regression\", LogisticRegression(C=0.0886)),\n",
    "              (\"SVM\", svm.SVC(probability=True, kernel=\"rbf\")),\n",
    "              (\"Naive Bayes\", GaussianNB())]\n",
    "\n",
    "voter = VotingClassifier(estimators, voting=\"soft\")\n",
    "\n",
    "voter.fit(X_train, y_train)\n",
    "\n",
    "roc_scorer = make_scorer(roc_auc_score)\n",
    "scores = cross_val_score(voter, X_train, y_train, scoring=roc_scorer, cv = 5)\n",
    "print(scores)\n",
    "print(\"mean:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = voter.predict(X_test)\n",
    "print(roc_auc_score(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
